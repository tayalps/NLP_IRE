{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"},"colab":{"name":"finetuned_roberta_sentiment.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"40ad2dad93fb4c9da05533bed1406b1d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_84380def22e04495a9877aa054a04ae1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f6f0cb2315264194bbf279e87a31f481","IPY_MODEL_3516bb655d134820b889ea67bed2b188"]}},"84380def22e04495a9877aa054a04ae1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f6f0cb2315264194bbf279e87a31f481":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_da50d84070d248a3b84c416fca0e69a0","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":3,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1a1b0f61c572447ebbb56a7a60dcc770"}},"3516bb655d134820b889ea67bed2b188":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_57dc8a854cf6437e874f6d04f922347a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3/3 [08:28&lt;00:00, 169.47s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1cf88d1629cb4953bb8a83dbc2648c3a"}},"da50d84070d248a3b84c416fca0e69a0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1a1b0f61c572447ebbb56a7a60dcc770":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"57dc8a854cf6437e874f6d04f922347a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1cf88d1629cb4953bb8a83dbc2648c3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ebc35a48adfd43398046a38eb64efe63":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8eaf979e848f4dd39e9b82493970ffd7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c711a9171d944dbd9d96eeb3a6f57227","IPY_MODEL_f9dff4ca1ed347c48158a921e080606d"]}},"8eaf979e848f4dd39e9b82493970ffd7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c711a9171d944dbd9d96eeb3a6f57227":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_97348e09d32d4d9ca6b92651a92095c3","_dom_classes":[],"description":"Epoch 1: 100%","_model_name":"FloatProgressModel","bar_style":"","max":225,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":225,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_30f0017ee4494fefbcbb009c28c76e96"}},"f9dff4ca1ed347c48158a921e080606d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f3c272d943fb47f4a89e4fb560625ded","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 225/225 [02:37&lt;00:00,  1.58it/s, training_loss=0.073]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1a1c6ab026ef4fb5bdda05854c6f2a06"}},"97348e09d32d4d9ca6b92651a92095c3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"30f0017ee4494fefbcbb009c28c76e96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f3c272d943fb47f4a89e4fb560625ded":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1a1c6ab026ef4fb5bdda05854c6f2a06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d90ff74346274e9aae6157e85f305a65":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_997d8dc61b3c429fa168673d1770e601","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e9705698928645779435674fc70ea437","IPY_MODEL_e1f00fbe66c248c698b063f22647ef26"]}},"997d8dc61b3c429fa168673d1770e601":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e9705698928645779435674fc70ea437":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0567285f0d1c4ed5826072d7c04d7345","_dom_classes":[],"description":"Epoch 2: 100%","_model_name":"FloatProgressModel","bar_style":"","max":225,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":225,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9e548641656640a09df372e62013fe52"}},"e1f00fbe66c248c698b063f22647ef26":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_35e8af27c44c4704a14d86c6aa4fdab9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 225/225 [02:42&lt;00:00,  1.57it/s, training_loss=0.092]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cb9e91d2abdf4209912c34e323442a54"}},"0567285f0d1c4ed5826072d7c04d7345":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9e548641656640a09df372e62013fe52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"35e8af27c44c4704a14d86c6aa4fdab9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"cb9e91d2abdf4209912c34e323442a54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1ceac738af114c508d428d0d66b7b2a2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_539cf2aea5b24aad95f92c74d11eda95","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e67a3bdd2fbb46df80c70aa317e4e628","IPY_MODEL_f92cf42d7a344394a1f78bb1a57a70f7"]}},"539cf2aea5b24aad95f92c74d11eda95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e67a3bdd2fbb46df80c70aa317e4e628":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c4c2556763df47cf9141c7fa68b990ca","_dom_classes":[],"description":"Epoch 3: 100%","_model_name":"FloatProgressModel","bar_style":"","max":225,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":225,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b71ccc7786d247ce9af7d626e3345fa7"}},"f92cf42d7a344394a1f78bb1a57a70f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_16ce1a498e224e0d883fbcd9f1aaf785","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 225/225 [02:41&lt;00:00,  1.56it/s, training_loss=0.163]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_234b31679126400da90b1dc4e86d4c85"}},"c4c2556763df47cf9141c7fa68b990ca":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b71ccc7786d247ce9af7d626e3345fa7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"16ce1a498e224e0d883fbcd9f1aaf785":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"234b31679126400da90b1dc4e86d4c85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"sv72A6q_8B0U"},"source":["# Sentiment Analysis using finetuned BERT model on financial documents 10K\n"]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"4IZv2XJM8B0b","executionInfo":{"status":"ok","timestamp":1604063898319,"user_tz":-330,"elapsed":4434,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}}},"source":["import torch\n","import pandas as pd\n","from tqdm.notebook import tqdm"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"XCxDygL89CQQ","executionInfo":{"status":"ok","timestamp":1604063938148,"user_tz":-330,"elapsed":38098,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"4156dc39-e2e1-4345-f3d2-8c8a071ea5f3","colab":{"base_uri":"https://localhost:8080/"}},"source":["#mount the drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"SRK0cI1w8B0f","executionInfo":{"status":"ok","timestamp":1604063943143,"user_tz":-330,"elapsed":2361,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"1aeac2e6-e5ae-4766-88be-2425ae0a456c","colab":{"base_uri":"https://localhost:8080/"}},"source":["import json \n","traind=[]\n","vald=[]\n","dir = \"/content/drive/My Drive/praveen_iiit_hyd_ire_class/ten_k_project_work/data/\"\n","# Opening JSON file \n","with open(dir+'FinNum_training_v3.json',) as f: \n","  traind = json.load(f) \n","with open(dir+'FinNum_dev_v3.json',) as f: \n","  vald = json.load(f) \n","\n","train = pd.DataFrame(traind) \n","val = pd.DataFrame(vald) \n","print(train.shape, val.shape)\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["(7187, 5) (1044, 5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LfOca6n1BYp8","executionInfo":{"status":"ok","timestamp":1603903823262,"user_tz":-330,"elapsed":671,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"f1acea7b-191a-4d7f-c5bd-fdb86371cfcc","colab":{"base_uri":"https://localhost:8080/","height":110}},"source":["train.head(2)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweet</th>\n","      <th>target_num</th>\n","      <th>offset</th>\n","      <th>target_cashtag</th>\n","      <th>relation</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>$XXII Scott Gottlieb, Commissioner of FDA spee...</td>\n","      <td>3</td>\n","      <td>74</td>\n","      <td>XXII</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>$TSLA Maybe they calculate that 7ct energy pri...</td>\n","      <td>7</td>\n","      <td>32</td>\n","      <td>TSLA</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               tweet  ... relation\n","0  $XXII Scott Gottlieb, Commissioner of FDA spee...  ...        1\n","1  $TSLA Maybe they calculate that 7ct energy pri...  ...        1\n","\n","[2 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"5CpJt29VBalA","executionInfo":{"status":"ok","timestamp":1603903825286,"user_tz":-330,"elapsed":974,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"dee72bd7-e88a-43e6-b45b-2106131003ce","colab":{"base_uri":"https://localhost:8080/","height":110}},"source":["val.head(2)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweet</th>\n","      <th>target_num</th>\n","      <th>offset</th>\n","      <th>target_cashtag</th>\n","      <th>relation</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>$CAT My ST alert at $121 now up a nice 19% if ...</td>\n","      <td>121</td>\n","      <td>21</td>\n","      <td>CAT</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>$CYTR Wondering if i should rather add Jul/Sep...</td>\n","      <td>1</td>\n","      <td>47</td>\n","      <td>CYTR</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               tweet  ... relation\n","0  $CAT My ST alert at $121 now up a nice 19% if ...  ...        1\n","1  $CYTR Wondering if i should rather add Jul/Sep...  ...        1\n","\n","[2 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"BZbP4hLi_sWC","executionInfo":{"status":"ok","timestamp":1603903827222,"user_tz":-330,"elapsed":1101,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"abb2e9be-ba09-486d-f095-7d9db59aa743","colab":{"base_uri":"https://localhost:8080/","height":451}},"source":["train.info(), val.info()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 7187 entries, 0 to 7186\n","Data columns (total 5 columns):\n"," #   Column          Non-Null Count  Dtype \n","---  ------          --------------  ----- \n"," 0   tweet           7187 non-null   object\n"," 1   target_num      7187 non-null   object\n"," 2   offset          7187 non-null   int64 \n"," 3   target_cashtag  7187 non-null   object\n"," 4   relation        7187 non-null   int64 \n","dtypes: int64(2), object(3)\n","memory usage: 280.9+ KB\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1044 entries, 0 to 1043\n","Data columns (total 5 columns):\n"," #   Column          Non-Null Count  Dtype \n","---  ------          --------------  ----- \n"," 0   tweet           1044 non-null   object\n"," 1   target_num      1044 non-null   object\n"," 2   offset          1044 non-null   int64 \n"," 3   target_cashtag  1044 non-null   object\n"," 4   relation        1044 non-null   int64 \n","dtypes: int64(2), object(3)\n","memory usage: 40.9+ KB\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(None, None)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"kaKydZxD_zwo","executionInfo":{"status":"ok","timestamp":1604063951809,"user_tz":-330,"elapsed":911,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}}},"source":["cols = ['tweet', 'relation']\n","train = train[cols]\n","val = val[cols]"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"zbfv7z_38B0n","executionInfo":{"status":"ok","timestamp":1604063954117,"user_tz":-330,"elapsed":1026,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"5d2c76f6-7c50-4619-d130-413442080400","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(train.relation.value_counts())\n","print(val.relation.value_counts())"],"execution_count":5,"outputs":[{"output_type":"stream","text":["1    5827\n","0    1360\n","Name: relation, dtype: int64\n","1    850\n","0    194\n","Name: relation, dtype: int64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6X4Uw-ZpOzmc","executionInfo":{"status":"ok","timestamp":1604063958786,"user_tz":-330,"elapsed":898,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}}},"source":["label_dict = {}\n","for index, possible_label in enumerate(train.relation.unique()):\n","    label_dict[possible_label] = index"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"TYc151KlO-Yx","executionInfo":{"status":"ok","timestamp":1604063962457,"user_tz":-330,"elapsed":915,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"34c07dd7-8c7d-4f53-e1d7-d25687e88b0c","colab":{"base_uri":"https://localhost:8080/"}},"source":["label_dict, len(label_dict)"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["({0: 1, 1: 0}, 2)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"KwHth1HS8B1C"},"source":["## Training/Validation Split"]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"5gf-8P2c8B1D","executionInfo":{"status":"ok","timestamp":1604063965287,"user_tz":-330,"elapsed":1039,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}}},"source":["from sklearn.model_selection import train_test_split"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"iE14PW7l8B1G"},"source":["X_train, X_val, y_train, y_val = train['tweet'], val['tweet'], train['relation'], val['relation']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"ywWKa-iT8B1j"},"source":["## Loading Tokenizer and Encoding our Data"]},{"cell_type":"code","metadata":{"id":"E722DOGNE9D_","executionInfo":{"status":"ok","timestamp":1604063974067,"user_tz":-330,"elapsed":6433,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"f2b2210d-6714-4623-ee52-2357d176be05","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip install transformers"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n","\u001b[K     |████████████████████████████████| 1.3MB 11.3MB/s \n","\u001b[?25hCollecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 59.0MB/s \n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 58.1MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Collecting tokenizers==0.9.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 53.2MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=48c682107624530c1aab379ebfcc83b13824a6562e134d1a5793035921564a80\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.9.2 transformers-3.4.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"KOJ8ulRl8B1k","executionInfo":{"status":"ok","timestamp":1604064083978,"user_tz":-330,"elapsed":999,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}}},"source":["#from transformers import BertTokenizer\n","from torch.utils.data import TensorDataset"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"uAXhkgalF4c0","executionInfo":{"status":"ok","timestamp":1604064151620,"user_tz":-330,"elapsed":803,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"6bdee140-153e-4583-c755-6a539ba6b8fe","colab":{"base_uri":"https://localhost:8080/"}},"source":["cd \"/content/drive/My Drive/praveen_iiit_hyd_ire_class/ten_k_project_work\""],"execution_count":14,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/praveen_iiit_hyd_ire_class/ten_k_project_work\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"F3iUh4ot8B1r","executionInfo":{"status":"ok","timestamp":1604064162398,"user_tz":-330,"elapsed":3127,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}}},"source":["from transformers import RobertaTokenizerFast\n","\n","tokenizer = RobertaTokenizerFast.from_pretrained(\"./tenkBERTo\", max_len=512, do_lower_case=True)\n"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"_OR6pydz8B1w","executionInfo":{"status":"ok","timestamp":1604064642054,"user_tz":-330,"elapsed":1829,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"f8db5531-5f7c-4a37-a2b6-ca253ff96229","colab":{"base_uri":"https://localhost:8080/"}},"source":["encoded_data_train = tokenizer.batch_encode_plus(\n","    train.tweet.tolist(), \n","    add_special_tokens=True, \n","    return_attention_mask=True, \n","    pad_to_max_length=True, \n","    max_length=256, \n","    return_tensors='pt'\n",")\n","\n","encoded_data_val = tokenizer.batch_encode_plus(\n","    val.tweet.tolist(), \n","    add_special_tokens=True, \n","    return_attention_mask=True, \n","    pad_to_max_length=True, \n","    max_length=256, \n","    return_tensors='pt'\n",")\n","\n","\n","input_ids_train = encoded_data_train['input_ids']\n","attention_masks_train = encoded_data_train['attention_mask']\n","labels_train = torch.tensor(train.relation.values)\n","\n","input_ids_val = encoded_data_val['input_ids']\n","attention_masks_val = encoded_data_val['attention_mask']\n","labels_val = torch.tensor(val.relation.values)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"mO8pioyH8B12","executionInfo":{"status":"ok","timestamp":1604064650038,"user_tz":-330,"elapsed":823,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}}},"source":["dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n","dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"-vb9-oM38B18","executionInfo":{"status":"ok","timestamp":1604064651646,"user_tz":-330,"elapsed":834,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"85b1c0fd-0f93-467f-b993-0abce544bbf6","colab":{"base_uri":"https://localhost:8080/"}},"source":["len(dataset_train), len(dataset_val)"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(7187, 1044)"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"Mm1lP0468B2G"},"source":["## Setting up BERT Pretrained Model"]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"eITaOyw68B2I","executionInfo":{"status":"ok","timestamp":1604064705119,"user_tz":-330,"elapsed":849,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}}},"source":["from transformers import RobertaForSequenceClassification"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"iSi1N1oG8B2N","executionInfo":{"status":"ok","timestamp":1604064747583,"user_tz":-330,"elapsed":8673,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"9ca9b0dc-79d3-4533-d86b-9b8fa2700dd4","colab":{"base_uri":"https://localhost:8080/"}},"source":["model = RobertaForSequenceClassification.from_pretrained('./tenkBERTo',\n","                                                      num_labels=len(label_dict),\n","                                                      output_attentions=False,\n","                                                      output_hidden_states=False)\n","\n"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at ./tenkBERTo were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ./tenkBERTo and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"jWlICZF58B2U"},"source":["## Creating Data Loaders"]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"i0Dt7YKX8B2V","executionInfo":{"status":"ok","timestamp":1604064754283,"user_tz":-330,"elapsed":832,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}}},"source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"tl48R3wv8B2b","executionInfo":{"status":"ok","timestamp":1604064755834,"user_tz":-330,"elapsed":840,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}}},"source":["batch_size = 32\n","\n","dataloader_train = DataLoader(dataset_train, \n","                              sampler=RandomSampler(dataset_train), \n","                              batch_size=batch_size)\n","\n","dataloader_validation = DataLoader(dataset_val, \n","                                   sampler=SequentialSampler(dataset_val), \n","                                   batch_size=batch_size)"],"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"SUj88P0h8B2g"},"source":["## Setting Up Optimiser and Scheduler"]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"Rzy_sM6i8B2h","executionInfo":{"status":"ok","timestamp":1604064761129,"user_tz":-330,"elapsed":837,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}}},"source":["from transformers import AdamW, get_linear_schedule_with_warmup"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"S-DseD4L8B2m","executionInfo":{"status":"ok","timestamp":1604064762711,"user_tz":-330,"elapsed":830,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}}},"source":["optimizer = AdamW(model.parameters(),\n","                  lr=1e-5, \n","                  eps=1e-8)"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"Ck1n-Sgs8B2t","executionInfo":{"status":"ok","timestamp":1604064764142,"user_tz":-330,"elapsed":847,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}}},"source":["epochs = 3\n","\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps=0,\n","                                            num_training_steps=len(dataloader_train)*epochs)"],"execution_count":31,"outputs":[]},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"QxIix4QE8B2x"},"source":["## Defining our Performance Metrics"]},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"9qNOy85W8B2y"},"source":["*Accuracy* metric approach originally used in accuracy function in [this tutorial](https://mccormickml.com/2019/07/22/BERT-fine-tuning/#41-bertforsequenceclassification)."]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"MwUM9UJq8B2z","executionInfo":{"status":"ok","timestamp":1604064769197,"user_tz":-330,"elapsed":1019,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}}},"source":["import numpy as np"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"AYQYO65b8B3D","executionInfo":{"status":"ok","timestamp":1604064769202,"user_tz":-330,"elapsed":638,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}}},"source":["from sklearn.metrics import f1_score"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"utkBPpyk8B3H","executionInfo":{"status":"ok","timestamp":1604064769602,"user_tz":-330,"elapsed":631,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}}},"source":["def f1_score_func(preds, labels):\n","    preds_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return f1_score(labels_flat, preds_flat, average='weighted')"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"OiURsnSj8B3L","executionInfo":{"status":"ok","timestamp":1604064770455,"user_tz":-330,"elapsed":639,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}}},"source":["def accuracy_per_class(preds, labels):\n","    label_dict_inverse = {v: k for k, v in label_dict.items()}\n","    \n","    preds_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","\n","    for label in np.unique(labels_flat):\n","        y_preds = preds_flat[labels_flat==label]\n","        y_true = labels_flat[labels_flat==label]\n","        print(f'Class: {label_dict_inverse[label]}')\n","        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"],"execution_count":35,"outputs":[]},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"lJWTwiBn8B3Q"},"source":["## Creating our Training Loop"]},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"Fbm8Fz6E8B3Q"},"source":["Approach adapted from an older version of HuggingFace's `run_glue.py` script. Accessible [here](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128)."]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"B7gSj9oG8B3R","executionInfo":{"status":"ok","timestamp":1604064774309,"user_tz":-330,"elapsed":875,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}}},"source":["import random\n","\n","seed_val = 17\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"_E0yEEnp8B3T","executionInfo":{"status":"ok","timestamp":1604064789494,"user_tz":-330,"elapsed":14378,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"b0deb832-f307-4eef-814a-a28e4dfc2456","colab":{"base_uri":"https://localhost:8080/"}},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","\n","print(device)"],"execution_count":37,"outputs":[{"output_type":"stream","text":["cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"1IyT19nI8B3W","executionInfo":{"status":"ok","timestamp":1604064792229,"user_tz":-330,"elapsed":852,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}}},"source":["def evaluate(dataloader_val):\n","\n","    model.eval()\n","    \n","    loss_val_total = 0\n","    predictions, true_vals = [], []\n","    \n","    for batch in dataloader_val:\n","        \n","        batch = tuple(b.to(device) for b in batch)\n","        \n","        inputs = {'input_ids':      batch[0],\n","                  'attention_mask': batch[1],\n","                  'labels':         batch[2],\n","                 }\n","\n","        with torch.no_grad():        \n","            outputs = model(**inputs)\n","            \n","        loss = outputs[0]\n","        logits = outputs[1]\n","        loss_val_total += loss.item()\n","\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = inputs['labels'].cpu().numpy()\n","        predictions.append(logits)\n","        true_vals.append(label_ids)\n","    \n","    loss_val_avg = loss_val_total/len(dataloader_val) \n","    \n","    predictions = np.concatenate(predictions, axis=0)\n","    true_vals = np.concatenate(true_vals, axis=0)\n","            \n","    return loss_val_avg, predictions, true_vals"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"4uzIhYoM8B3Z","executionInfo":{"status":"ok","timestamp":1604065302657,"user_tz":-330,"elapsed":509331,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"94dab3bc-7c67-4d66-de0a-5e4f3bbfcf42","colab":{"base_uri":"https://localhost:8080/","height":327,"referenced_widgets":["40ad2dad93fb4c9da05533bed1406b1d","84380def22e04495a9877aa054a04ae1","f6f0cb2315264194bbf279e87a31f481","3516bb655d134820b889ea67bed2b188","da50d84070d248a3b84c416fca0e69a0","1a1b0f61c572447ebbb56a7a60dcc770","57dc8a854cf6437e874f6d04f922347a","1cf88d1629cb4953bb8a83dbc2648c3a","ebc35a48adfd43398046a38eb64efe63","8eaf979e848f4dd39e9b82493970ffd7","c711a9171d944dbd9d96eeb3a6f57227","f9dff4ca1ed347c48158a921e080606d","97348e09d32d4d9ca6b92651a92095c3","30f0017ee4494fefbcbb009c28c76e96","f3c272d943fb47f4a89e4fb560625ded","1a1c6ab026ef4fb5bdda05854c6f2a06","d90ff74346274e9aae6157e85f305a65","997d8dc61b3c429fa168673d1770e601","e9705698928645779435674fc70ea437","e1f00fbe66c248c698b063f22647ef26","0567285f0d1c4ed5826072d7c04d7345","9e548641656640a09df372e62013fe52","35e8af27c44c4704a14d86c6aa4fdab9","cb9e91d2abdf4209912c34e323442a54","1ceac738af114c508d428d0d66b7b2a2","539cf2aea5b24aad95f92c74d11eda95","e67a3bdd2fbb46df80c70aa317e4e628","f92cf42d7a344394a1f78bb1a57a70f7","c4c2556763df47cf9141c7fa68b990ca","b71ccc7786d247ce9af7d626e3345fa7","16ce1a498e224e0d883fbcd9f1aaf785","234b31679126400da90b1dc4e86d4c85"]}},"source":["for epoch in tqdm(range(1, epochs+1)):\n","    \n","    model.train()\n","    \n","    loss_train_total = 0\n","\n","    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n","    for batch in progress_bar:\n","\n","        model.zero_grad()\n","        \n","        batch = tuple(b.to(device) for b in batch)\n","        \n","        inputs = {'input_ids':      batch[0],\n","                  'attention_mask': batch[1],\n","                  'labels':         batch[2],\n","                 }       \n","\n","        outputs = model(**inputs)\n","        \n","        loss = outputs[0]\n","        loss_train_total += loss.item()\n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        optimizer.step()\n","        scheduler.step()\n","        \n","        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n","         \n","        \n","    torch.save(model.state_dict(), f'finetuned_BERT_epoch_{epoch}.model')\n","        \n","    tqdm.write(f'\\nEpoch {epoch}')\n","    \n","    loss_train_avg = loss_train_total/len(dataloader_train)            \n","    tqdm.write(f'Training loss: {loss_train_avg}')\n","    \n","    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n","    val_f1 = f1_score_func(predictions, true_vals)\n","    tqdm.write(f'Validation loss: {val_loss}')\n","    tqdm.write(f'F1 Score (Weighted): {val_f1}')"],"execution_count":39,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"40ad2dad93fb4c9da05533bed1406b1d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ebc35a48adfd43398046a38eb64efe63","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=225.0, style=ProgressStyle(description_widt…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r\n","Epoch 1\n","Training loss: 0.4035102525022295\n","Validation loss: 0.2340839940941695\n","F1 Score (Weighted): 0.9039124746689672\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d90ff74346274e9aae6157e85f305a65","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Epoch 2', max=225.0, style=ProgressStyle(description_widt…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r\n","Epoch 2\n","Training loss: 0.3502517963118023\n","Validation loss: 0.2736813339658759\n","F1 Score (Weighted): 0.8711520878578454\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1ceac738af114c508d428d0d66b7b2a2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Epoch 3', max=225.0, style=ProgressStyle(description_widt…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r\n","Epoch 3\n","Training loss: 0.3225500489274661\n","Validation loss: 0.25702367762498785\n","F1 Score (Weighted): 0.8805923698779573\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"aQI2qpwL8B3j","executionInfo":{"status":"ok","timestamp":1604065956920,"user_tz":-330,"elapsed":8728,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}}},"source":["_, predictions, true_vals = evaluate(dataloader_validation)"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"z-ik2GuR8B3n","executionInfo":{"status":"ok","timestamp":1604065959778,"user_tz":-330,"elapsed":823,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"1aa5a92e-4e23-45c3-b086-e4c18c3b142c","colab":{"base_uri":"https://localhost:8080/"}},"source":["accuracy_per_class(predictions, true_vals)"],"execution_count":41,"outputs":[{"output_type":"stream","text":["Class: 1\n","Accuracy: 88/194\n","\n","Class: 0\n","Accuracy: 848/850\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"KNKuvGlH8B3q"},"source":[""],"execution_count":null,"outputs":[]}]}