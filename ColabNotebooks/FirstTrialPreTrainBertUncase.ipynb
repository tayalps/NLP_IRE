{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FirstTrialPreTrainBertUncase.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNqhxR9I9eTBzAJBhnIXHUZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"8k77V3aUo05Y"},"source":["import torch\n","import gc\n","\n","gc.collect()\n","torch.cuda.empty_cache()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3OTNrloVRsFj","executionInfo":{"status":"ok","timestamp":1603894581712,"user_tz":-330,"elapsed":2851,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"c6bfc5a0-15e9-4168-924e-8d7d3efa758a","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["#mount the drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vBtiJ9WPLBZu"},"source":["Need to have higher version of pyarrow"]},{"cell_type":"code","metadata":{"id":"C28wNcNpUnuz","executionInfo":{"status":"ok","timestamp":1603894100668,"user_tz":-330,"elapsed":13168,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"65783f34-8f44-4434-e46f-3f8dd4b18e22","colab":{"base_uri":"https://localhost:8080/","height":193}},"source":["!pip install --upgrade pyarrow"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pyarrow\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e1/27958a70848f8f7089bff8d6ebe42519daf01f976d28b481e1bfd52c8097/pyarrow-2.0.0-cp36-cp36m-manylinux2014_x86_64.whl (17.7MB)\n","\u001b[K     |████████████████████████████████| 17.7MB 198kB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from pyarrow) (1.18.5)\n","Installing collected packages: pyarrow\n","  Found existing installation: pyarrow 0.14.1\n","    Uninstalling pyarrow-0.14.1:\n","      Successfully uninstalled pyarrow-0.14.1\n","Successfully installed pyarrow-2.0.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"igGf-IhJLG8-"},"source":["## Clone the hugging face transformers code"]},{"cell_type":"code","metadata":{"id":"AFI3EjNoRtz0","executionInfo":{"status":"ok","timestamp":1603894145046,"user_tz":-330,"elapsed":10278,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"18506710-0af3-4815-c21c-a3e313491b9a","colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["!git clone https://github.com/huggingface/transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'transformers'...\n","remote: Enumerating objects: 63, done.\u001b[K\n","remote: Counting objects: 100% (63/63), done.\u001b[K\n","remote: Compressing objects: 100% (39/39), done.\u001b[K\n","remote: Total 48362 (delta 32), reused 42 (delta 21), pack-reused 48299\u001b[K\n","Receiving objects: 100% (48362/48362), 35.57 MiB | 13.28 MiB/s, done.\n","Resolving deltas: 100% (33706/33706), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Nc6TTbYgR5Qc","executionInfo":{"status":"ok","timestamp":1603894150784,"user_tz":-330,"elapsed":1467,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"c9ee4209-db1f-4cb5-af64-86026abb24c6","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["cd transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/transformers\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"elHGGSpXR_3D","executionInfo":{"status":"ok","timestamp":1603894154646,"user_tz":-330,"elapsed":1174,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"31ef0bb3-8371-47e4-d9f4-e78688e367b9","colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["!ls\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CODE_OF_CONDUCT.md  hubconf.py\t notebooks\t setup.py   valohai.yaml\n","CONTRIBUTING.md     LICENSE\t pyproject.toml  src\n","docker\t\t    Makefile\t README.md\t templates\n","docs\t\t    MANIFEST.in  scripts\t tests\n","examples\t    model_cards  setup.cfg\t utils\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ri-Cl-SsLQOm"},"source":["###Install all the required libraries needed to run the transformers. After installation restart the kernel to enable the effect of newly installed or upgraded libraries"]},{"cell_type":"code","metadata":{"id":"sKfv4hywSBIA","executionInfo":{"status":"ok","timestamp":1603894207263,"user_tz":-330,"elapsed":50856,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"dbdf5841-1f9d-456b-c413-ba4323a55762","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!pip install .\n","!pip install -r ./examples/requirements.txt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Processing /content/transformers\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (1.18.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (4.41.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (2019.12.20)\n","Collecting sentencepiece==0.1.91\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 7.1MB/s \n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (3.12.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (20.4)\n","Collecting tokenizers==0.9.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 23.5MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 35.8MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (2.23.0)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (0.7)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers==3.4.0) (50.3.0)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers==3.4.0) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.4.0) (2.4.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.4.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.4.0) (0.17.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (1.24.3)\n","Building wheels for collected packages: transformers\n","  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformers: filename=transformers-3.4.0-cp36-none-any.whl size=1278393 sha256=a9856d9e8c814d1d22c6cb72f53694a8a7ac4803c1d3408e9e7059f479f40743\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-dwghrecn/wheels/23/19/dd/2561a4e47240cf6b307729d58e56f8077dd0c698f5992216cf\n","Successfully built transformers\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=5f3cda93b62de1786b23b6ab6e35b732647d6faf58e04f4d4b5fb7cc22b56b03\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.2 transformers-3.4.0\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from -r ./examples/requirements.txt (line 1)) (2.3.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from -r ./examples/requirements.txt (line 2)) (0.22.2.post1)\n","Collecting seqeval\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n","\u001b[K     |████████████████████████████████| 51kB 3.2MB/s \n","\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from -r ./examples/requirements.txt (line 4)) (5.4.8)\n","Collecting sacrebleu\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/c4/8e948f601a4f9609e8b2b58f31966cb13cf17b940b82aa3e767f01c42c52/sacrebleu-1.4.14-py3-none-any.whl (64kB)\n","\u001b[K     |████████████████████████████████| 71kB 6.3MB/s \n","\u001b[?25hCollecting rouge-score\n","  Downloading https://files.pythonhosted.org/packages/1f/56/a81022436c08b9405a5247b71635394d44fe7e1dbedc4b28c740e09c2840/rouge_score-0.0.4-py2.py3-none-any.whl\n","Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.6/dist-packages (from -r ./examples/requirements.txt (line 7)) (4.0.1)\n","Collecting pytorch-lightning==0.9.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/af/2f10c8ee22d7a05fe8c9be58ad5c55b71ab4dd895b44f0156bfd5535a708/pytorch_lightning-0.9.0-py3-none-any.whl (408kB)\n","\u001b[K     |████████████████████████████████| 409kB 12.5MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from -r ./examples/requirements.txt (line 9)) (3.2.2)\n","Collecting git-python==1.0.3\n","  Downloading https://files.pythonhosted.org/packages/8a/de/0cc6353a45cdb1e137cffac5383097b300cc578e2e1133eeb847e23a1394/git_python-1.0.3-py2.py3-none-any.whl\n","Collecting faiss-cpu\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/6b/51321f5b34507dc1cb2b17e02e740acacd4ac818ed4b66670c24dd71347b/faiss_cpu-1.6.4-cp36-cp36m-manylinux2014_x86_64.whl (7.9MB)\n","\u001b[K     |████████████████████████████████| 7.9MB 10.7MB/s \n","\u001b[?25hCollecting streamlit\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/d2/3228e647441606a38ce4f73a30ba8a5d36a7be421123d129f7e40348dc02/streamlit-0.69.2-py2.py3-none-any.whl (7.4MB)\n","\u001b[K     |████████████████████████████████| 7.4MB 38.9MB/s \n","\u001b[?25hCollecting elasticsearch\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e4/b7/f8f03019089671486e2910282c1b6fce26ccc8a513322df72ac8994ab2de/elasticsearch-7.9.1-py2.py3-none-any.whl (219kB)\n","\u001b[K     |████████████████████████████████| 225kB 41.8MB/s \n","\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from -r ./examples/requirements.txt (line 14)) (3.2.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from -r ./examples/requirements.txt (line 15)) (1.1.3)\n","Collecting datasets\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/f4/2a3d6aee93ae7fce6c936dda2d7f534ad5f044a21238f85e28f0b205adf0/datasets-1.1.2-py3-none-any.whl (147kB)\n","\u001b[K     |████████████████████████████████| 153kB 40.8MB/s \n","\u001b[?25hCollecting fire\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/a7/0e22e70778aca01a52b9c899d9c145c6396d7b613719cd63db97ffa13f2f/fire-0.3.1.tar.gz (81kB)\n","\u001b[K     |████████████████████████████████| 81kB 10.4MB/s \n","\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from -r ./examples/requirements.txt (line 18)) (3.6.4)\n","Collecting conllu\n","  Downloading https://files.pythonhosted.org/packages/1c/20/39bf21e3a0304c874c40c9cec96e3f70d2ef4b1ada3585f7dbee91dc8c05/conllu-4.2.1-py2.py3-none-any.whl\n","Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from -r ./examples/requirements.txt (line 20)) (0.1.91)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (3.12.4)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (0.35.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (0.4.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (2.23.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (1.0.1)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (1.18.5)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (1.33.1)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (1.17.2)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (50.3.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (3.3.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (1.7.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (1.15.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (0.10.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r ./examples/requirements.txt (line 2)) (0.17.0)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r ./examples/requirements.txt (line 2)) (1.4.1)\n","Collecting portalocker\n","  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (0.16.0)\n","Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (2.3)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (1.1.0)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (0.7)\n","Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (3.1.0)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (0.24.0)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (20.2.0)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (0.1.5)\n","Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (0.3.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (4.41.1)\n","Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==0.9.0->-r ./examples/requirements.txt (line 8)) (1.6.0+cu101)\n","Collecting PyYAML>=5.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n","\u001b[K     |████████████████████████████████| 276kB 41.8MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==0.9.0->-r ./examples/requirements.txt (line 8)) (20.4)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r ./examples/requirements.txt (line 9)) (1.2.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r ./examples/requirements.txt (line 9)) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r ./examples/requirements.txt (line 9)) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r ./examples/requirements.txt (line 9)) (2.4.7)\n","Collecting gitpython\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/d1/a7f8fe3df258549b303415157328bfcc63e9b11d06a7ad7a3327f3d32606/GitPython-3.1.11-py3-none-any.whl (159kB)\n","\u001b[K     |████████████████████████████████| 163kB 36.5MB/s \n","\u001b[?25hRequirement already satisfied: astor in /usr/local/lib/python3.6/dist-packages (from streamlit->-r ./examples/requirements.txt (line 12)) (0.8.1)\n","Collecting enum-compat\n","  Downloading https://files.pythonhosted.org/packages/55/ae/467bc4509246283bb59746e21a1a2f5a8aecbef56b1fa6eaca78cd438c8b/enum_compat-0.0.3-py3-none-any.whl\n","Collecting validators\n","  Downloading https://files.pythonhosted.org/packages/41/4a/3360ff3cf2b4a1b9721ac1fbff5f84663f41047d9874b3aa1ac82e862c44/validators-0.18.1-py3-none-any.whl\n","Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.6/dist-packages (from streamlit->-r ./examples/requirements.txt (line 12)) (5.1.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from streamlit->-r ./examples/requirements.txt (line 12)) (7.0.0)\n","Requirement already satisfied: toml in /usr/local/lib/python3.6/dist-packages (from streamlit->-r ./examples/requirements.txt (line 12)) (0.10.1)\n","Collecting boto3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/d9/e8a56bd0953914f60207af4c41bb3947c47ca03577b1fe26258249dd9af7/boto3-1.16.6-py2.py3-none-any.whl (129kB)\n","\u001b[K     |████████████████████████████████| 133kB 33.7MB/s \n","\u001b[?25hCollecting watchdog\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/06/121302598a4fc01aca942d937f4a2c33430b7181137b35758913a8db10ad/watchdog-0.10.3.tar.gz (94kB)\n","\u001b[K     |████████████████████████████████| 102kB 10.1MB/s \n","\u001b[?25hCollecting base58\n","  Downloading https://files.pythonhosted.org/packages/3c/03/58572025c77b9e6027155b272a1b96298e711cd4f95c24967f7137ab0c4b/base58-2.0.1-py3-none-any.whl\n","Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.6/dist-packages (from streamlit->-r ./examples/requirements.txt (line 12)) (4.1.1)\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.6/dist-packages (from streamlit->-r ./examples/requirements.txt (line 12)) (2.0.0)\n","Collecting blinker\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/51/e2a9f3b757eb802f61dc1f2b09c8c99f6eb01cf06416c0671253536517b6/blinker-1.4.tar.gz (111kB)\n","\u001b[K     |████████████████████████████████| 112kB 41.4MB/s \n","\u001b[?25hCollecting pydeck>=0.1.dev5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/9d/8fbf1f56cc5891e6c3295bf94fc176e9ab0a3ffdd090cc8b354ac2640f9a/pydeck-0.5.0-py2.py3-none-any.whl (4.5MB)\n","\u001b[K     |████████████████████████████████| 4.5MB 35.2MB/s \n","\u001b[?25hCollecting botocore>=1.13.44\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/6c/f5b074e14823f250e0a73e53714c1ed80d689d530468936d35a9d336f1dd/botocore-1.19.6-py2.py3-none-any.whl (6.7MB)\n","\u001b[K     |████████████████████████████████| 6.7MB 35.5MB/s \n","\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from streamlit->-r ./examples/requirements.txt (line 12)) (7.1.2)\n","Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from streamlit->-r ./examples/requirements.txt (line 12)) (4.1.0)\n","Requirement already satisfied: tzlocal in /usr/local/lib/python3.6/dist-packages (from streamlit->-r ./examples/requirements.txt (line 12)) (1.5.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from elasticsearch->-r ./examples/requirements.txt (line 13)) (2020.6.20)\n","Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from elasticsearch->-r ./examples/requirements.txt (line 13)) (1.24.3)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r ./examples/requirements.txt (line 15)) (2018.9)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.6/dist-packages (from datasets->-r ./examples/requirements.txt (line 16)) (0.70.10)\n","Collecting xxhash\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/73/826b19f3594756cb1c6c23d2fbd8ca6a77a9cd3b650c9dec5acc85004c38/xxhash-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (242kB)\n","\u001b[K     |████████████████████████████████| 245kB 34.3MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from datasets->-r ./examples/requirements.txt (line 16)) (3.0.12)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->-r ./examples/requirements.txt (line 18)) (0.7.1)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r ./examples/requirements.txt (line 18)) (8.5.0)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r ./examples/requirements.txt (line 18)) (1.4.0)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r ./examples/requirements.txt (line 18)) (1.9.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r ./examples/requirements.txt (line 1)) (1.3.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r ./examples/requirements.txt (line 1)) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r ./examples/requirements.txt (line 1)) (2.10)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r ./examples/requirements.txt (line 1)) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r ./examples/requirements.txt (line 1)) (4.6)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard->-r ./examples/requirements.txt (line 1)) (2.0.0)\n","Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (3.3.1)\n","Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (1.52.0)\n","Collecting gitdb<5,>=4.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n","\u001b[K     |████████████████████████████████| 71kB 7.4MB/s \n","\u001b[?25hRequirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from validators->streamlit->-r ./examples/requirements.txt (line 12)) (4.4.2)\n","Collecting s3transfer<0.4.0,>=0.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n","\u001b[K     |████████████████████████████████| 71kB 7.4MB/s \n","\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n","  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n","Collecting pathtools>=0.1.1\n","  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n","Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.6/dist-packages (from pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (7.5.1)\n","Requirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.6/dist-packages (from pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (4.3.3)\n","Collecting ipykernel>=5.1.2; python_version >= \"3.4\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/19/c2812690d8b340987eecd2cbc18549b1d130b94c5d97fcbe49f5f8710edf/ipykernel-5.3.4-py3-none-any.whl (120kB)\n","\u001b[K     |████████████████████████████████| 122kB 40.1MB/s \n","\u001b[?25hRequirement already satisfied: jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (2.11.2)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.6/dist-packages (from altair>=3.2.0->streamlit->-r ./examples/requirements.txt (line 12)) (0.11.1)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from altair>=3.2.0->streamlit->-r ./examples/requirements.txt (line 12)) (0.3)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from altair>=3.2.0->streamlit->-r ./examples/requirements.txt (line 12)) (2.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r ./examples/requirements.txt (line 1)) (3.1.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->-r ./examples/requirements.txt (line 1)) (0.4.8)\n","Collecting smmap<4,>=3.0.1\n","  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n","Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (5.5.0)\n","Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (5.0.8)\n","Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (3.5.1)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.2->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (0.2.0)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (5.3.5)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.10.1->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (1.1.1)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (1.0.18)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (0.8.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (0.7.5)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (2.6.1)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (4.8.0)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (4.6.3)\n","Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (5.3.1)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (19.0.2)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (0.2.5)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (0.6.0)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (1.5.0)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (0.9.1)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (5.6.1)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (0.6.0)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (0.8.4)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (3.2.1)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (0.4.4)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (1.4.2)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r ./examples/requirements.txt (line 12)) (0.5.1)\n","Building wheels for collected packages: seqeval, fire, PyYAML, watchdog, blinker, pathtools\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-cp36-none-any.whl size=16171 sha256=4cea144993e32d0d5fe4e3b2b9bc4431b894835489983be878a6805fee06f3c7\n","  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.3.1-py2.py3-none-any.whl size=111005 sha256=58b657b14cd01204e1c40d190ad08041cc70fbd4451eb37a24a25c3dd7bbe116\n","  Stored in directory: /root/.cache/pip/wheels/c1/61/df/768b03527bf006b546dce284eb4249b185669e65afc5fbb2ac\n","  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44619 sha256=376991bfa4377492bcd45d9ce39380b8f0336307c7db200dc7864da876e0c662\n","  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n","  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for watchdog: filename=watchdog-0.10.3-cp36-none-any.whl size=73873 sha256=1764fb4fe858847626f550dc4ada37899c44df125d2e7e610d7946d4580caebf\n","  Stored in directory: /root/.cache/pip/wheels/a8/1d/38/2c19bb311f67cc7b4d07a2ec5ea36ab1a0a0ea50db994a5bc7\n","  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for blinker: filename=blinker-1.4-cp36-none-any.whl size=13450 sha256=8f63f9b66a308741e5b5034b00856f973ee0deeacf3b08bbdf1e616c632f335a\n","  Stored in directory: /root/.cache/pip/wheels/92/a0/00/8690a57883956a301d91cf4ec999cc0b258b01e3f548f86e89\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8785 sha256=c6b074eee2aa4fe45531bcf971d321f74bb8358fe188e871e99f43a5d5b8b181\n","  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n","Successfully built seqeval fire PyYAML watchdog blinker pathtools\n","\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 5.3.4 which is incompatible.\u001b[0m\n","\u001b[31mERROR: pytorch-lightning 0.9.0 has requirement future>=0.17.1, but you'll have future 0.16.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: pytorch-lightning 0.9.0 has requirement tensorboard==2.2.0, but you'll have tensorboard 2.3.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: botocore 1.19.6 has requirement urllib3<1.26,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n","Installing collected packages: seqeval, portalocker, sacrebleu, rouge-score, PyYAML, pytorch-lightning, smmap, gitdb, gitpython, git-python, faiss-cpu, enum-compat, validators, jmespath, botocore, s3transfer, boto3, pathtools, watchdog, base58, blinker, ipykernel, pydeck, streamlit, elasticsearch, xxhash, datasets, fire, conllu\n","  Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Found existing installation: ipykernel 4.10.1\n","    Uninstalling ipykernel-4.10.1:\n","      Successfully uninstalled ipykernel-4.10.1\n","Successfully installed PyYAML-5.3.1 base58-2.0.1 blinker-1.4 boto3-1.16.6 botocore-1.19.6 conllu-4.2.1 datasets-1.1.2 elasticsearch-7.9.1 enum-compat-0.0.3 faiss-cpu-1.6.4 fire-0.3.1 git-python-1.0.3 gitdb-4.0.5 gitpython-3.1.11 ipykernel-5.3.4 jmespath-0.10.0 pathtools-0.1.2 portalocker-2.0.0 pydeck-0.5.0 pytorch-lightning-0.9.0 rouge-score-0.0.4 s3transfer-0.3.3 sacrebleu-1.4.14 seqeval-1.2.2 smmap-3.0.4 streamlit-0.69.2 validators-0.18.1 watchdog-0.10.3 xxhash-2.0.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["ipykernel"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"mYNiBzzdSLtL","executionInfo":{"status":"ok","timestamp":1603891629468,"user_tz":-330,"elapsed":1418,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"ede5c377-083b-497b-980f-161a86391e04","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["!pwd"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8uOJBt0NTFHO","executionInfo":{"status":"ok","timestamp":1603891633972,"user_tz":-330,"elapsed":1203,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"9920ace8-f1cc-481b-d169-0d94d66840c9","colab":{"base_uri":"https://localhost:8080/","height":173}},"source":["!dir /content/transformers/examples/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["adversarial\t     lightning_base.py\t seq2seq\n","benchmarking\t     longform-qa\t test_examples.py\n","bert-loses-patience  lxmert\t\t test_xla_examples.py\n","bertology\t     movement-pruning\t text-classification\n","conftest.py\t     multiple-choice\t text-generation\n","contrib\t\t     question-answering  token-classification\n","deebert\t\t     rag\t\t xla_spawn.py\n","distillation\t     README.md\n","language-modeling    requirements.txt\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"U7QUFS_DLdqs"},"source":["## Copy the 10K file <- to be used as input for fine tuning the Bert LM model"]},{"cell_type":"code","metadata":{"id":"PZp2DwDCUDN2","executionInfo":{"status":"ok","timestamp":1603891640425,"user_tz":-330,"elapsed":1175,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"86a6bf4c-fdcf-4e7e-9db3-c794c560ea40","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["cd \"/content/drive/My Drive/praveen_iiit_hyd_ire_class/ten_k_project_work\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/praveen_iiit_hyd_ire_class/ten_k_project_work\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V5serfy7H8VD"},"source":["!mkdir \"/input_data\"\n","!mkdir \"/outputs\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2UdfPcMYIX59","executionInfo":{"status":"ok","timestamp":1603894596503,"user_tz":-330,"elapsed":4401,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"d2f6ff8a-691f-4559-cef6-59b040e7ce49","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["!cp \"/content/drive/My Drive/praveen_iiit_hyd_ire_class/ten_k_project_work/tenk_input_old.txt\" /input_data\n","!du -s -h /input_data/*"],"execution_count":null,"outputs":[{"output_type":"stream","text":["4.3M\t/input_data/tenk_input_old.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ylb7I4xgI1rK","executionInfo":{"status":"ok","timestamp":1603894600271,"user_tz":-330,"elapsed":1171,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"a6baa3aa-0e50-412e-bd9c-700d02de4d6f","colab":{"base_uri":"https://localhost:8080/","height":364}},"source":["!head -n 20 /input_data/tenk_input_old.txt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["213898 GrossFileSize\r\n","NetFileSize 137834\r\n","HTML_Chars 836\r\n","hdr 19940829 sgml\r\n","CONFORMED 10-K SUBMISSION TYPE\r\n","DOCUMENT PUBLIC COUNT\r\n","CONFORMED PERIOD 19940531 REPORT\r\n","19940824 DATE FILED\r\n","NAME CONFORMED COMPANY AAR CORP\r\n","CENTRAL INDEX KEY 1750\r\n","STANDARD INDUSTRIAL CLASSIFICATION 5080\r\n","IRS 362334820 NUMBER\r\n","YEAR END FISCAL 531\r\n","TYPE FORM 10-K\r\n","Act 1934 ACT SEC\r\n","FILE NUMBER SEC 1-06263\r\n","FILM NUMBER 94545798\r\n","1111 NICHOLAS BLVD STREET\r\n","CITY VILLAGE ELK GROVE\r\n","7084393939 BUSINESS PHONE\r\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wzagoFtFJeQc","executionInfo":{"status":"ok","timestamp":1603893160464,"user_tz":-330,"elapsed":1228,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"b118f7e8-0391-491d-f045-ab1a8006c4e1","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["!ls /content/transformers/examples/language-modeling"],"execution_count":null,"outputs":[{"output_type":"stream","text":["chinese_ref.py\tREADME.md  run_language_modeling.py\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dlUylhsTLqhY"},"source":["# Execute fine tuning"]},{"cell_type":"code","metadata":{"id":"d5P6ZJKTTGFS","executionInfo":{"status":"ok","timestamp":1603895196476,"user_tz":-330,"elapsed":422751,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"7caac2ac-ca0b-40f7-f521-88b1116485f9","colab":{"base_uri":"https://localhost:8080/","height":627}},"source":["import timeit\n","\n","start = timeit.default_timer() \n","\n","!python /content/transformers/examples/language-modeling/run_language_modeling.py \\\n","    --output_dir=/outputs \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-base-uncased \\\n","    --do_train \\\n","    --train_data_file=/input_data/tenk_input_old.txt \\\n","    --do_eval \\\n","    --eval_data_file=/input_data/tenk_input_old.txt \\\n","    --num_train_epochs=1 \\\n","    --save_steps=400 \\\n","    --mlm\n","\n","stop = timeit.default_timer()\n","print (stop - start)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-10-28 14:19:35.042983: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","10/28/2020 14:19:37 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n","10/28/2020 14:19:37 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='/outputs', overwrite_output_dir=False, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Oct28_14-19-37_250bd44e4e29', logging_first_step=False, logging_steps=500, save_steps=400, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='/outputs', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n","10/28/2020 14:19:37 - INFO - filelock -   Lock 140363826367064 acquired on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n","Downloading: 100% 433/433 [00:00<00:00, 344kB/s]\n","10/28/2020 14:19:37 - INFO - filelock -   Lock 140363826367064 released on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n","10/28/2020 14:19:38 - INFO - filelock -   Lock 140363826365608 acquired on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n","Downloading: 100% 232k/232k [00:00<00:00, 926kB/s] \n","10/28/2020 14:19:39 - INFO - filelock -   Lock 140363826365608 released on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n","/usr/local/lib/python3.6/dist-packages/transformers/modeling_auto.py:822: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n","  FutureWarning,\n","10/28/2020 14:19:39 - INFO - filelock -   Lock 140363826804384 acquired on /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n","Downloading: 100% 440M/440M [00:08<00:00, 51.2MB/s]\n","10/28/2020 14:19:48 - INFO - filelock -   Lock 140363826804384 released on /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1421: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","10/28/2020 14:19:52 - INFO - filelock -   Lock 140363533252032 acquired on /input_data/cached_lm_BertTokenizer_510_tenk_input_old.txt.lock\n","10/28/2020 14:20:07 - INFO - filelock -   Lock 140363533252032 released on /input_data/cached_lm_BertTokenizer_510_tenk_input_old.txt.lock\n","10/28/2020 14:20:07 - INFO - filelock -   Lock 140363533953624 acquired on /input_data/cached_lm_BertTokenizer_510_tenk_input_old.txt.lock\n","10/28/2020 14:20:07 - INFO - filelock -   Lock 140363533953624 released on /input_data/cached_lm_BertTokenizer_510_tenk_input_old.txt.lock\n","/usr/local/lib/python3.6/dist-packages/transformers/trainer.py:281: FutureWarning: Passing `prediction_loss_only` as a keyword argument is deprecated and won't be possible in a future version. Use `args.prediction_loss_only` instead. Setting `args.prediction_loss_only=True\n","  FutureWarning,\n","{'epoch': 1.0}\n","100% 155/155 [04:36<00:00,  1.78s/it]\n","/usr/local/lib/python3.6/dist-packages/transformers/trainer.py:1170: FutureWarning: This method is deprecated, use `Trainer.is_world_process_zero()` instead.\n","  warnings.warn(\"This method is deprecated, use `Trainer.is_world_process_zero()` instead.\", FutureWarning)\n","10/28/2020 14:24:57 - INFO - __main__ -   *** Evaluate ***\n","100% 155/155 [01:36<00:00,  1.61it/s]\n","10/28/2020 14:26:34 - INFO - __main__ -   ***** Eval results *****\n","10/28/2020 14:26:34 - INFO - __main__ -     perplexity = 94.9182681237932\n","421.49104870400015\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n4_PQaVYKdDI","executionInfo":{"status":"ok","timestamp":1603895227440,"user_tz":-330,"elapsed":1443,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"0b10ee28-8b24-4491-b87a-c9f37e64c433","colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["!du -s -h /outputs/*"],"execution_count":null,"outputs":[{"output_type":"stream","text":["4.0K\t/outputs/config.json\n","4.0K\t/outputs/eval_results_lm.txt\n","418M\t/outputs/pytorch_model.bin\n","4.0K\t/outputs/special_tokens_map.json\n","4.0K\t/outputs/tokenizer_config.json\n","4.0K\t/outputs/training_args.bin\n","228K\t/outputs/vocab.txt\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Qd96T-XyLws3"},"source":["## Copy the fine tuned model to the folder <- this new model will be used in all the downstream intrinsic and extrinsic tasks"]},{"cell_type":"code","metadata":{"id":"j_iDn4W8PM3Y"},"source":["!cp /outputs/* \"/content/drive/My Drive/praveen_iiit_hyd_ire_class/ten_k_project_work/output/\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_tD67ZGxNrl7","executionInfo":{"status":"ok","timestamp":1603895254671,"user_tz":-330,"elapsed":3576,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"d8c54ac0-6500-4aae-a9f1-cb3a2c84c550","colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["import glob\n","import os\n","from transformers import WEIGHTS_NAME\n","print(WEIGHTS_NAME)\n","directory_cpt = list(os.path.dirname(c) for c in sorted(glob.glob(\"/outputs\" + \"/**/\" + WEIGHTS_NAME, recursive=True)))\n","print(directory_cpt)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["pytorch_model.bin\n","['/outputs']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"r6yVOzsFOY7b","executionInfo":{"status":"ok","timestamp":1603895267451,"user_tz":-330,"elapsed":1556,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"fd3e241d-6e26-4f4e-8b1b-bde439685a06","colab":{"base_uri":"https://localhost:8080/","height":191}},"source":["!head -n 10 /outputs/vocab.txt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[PAD]\n","[unused0]\n","[unused1]\n","[unused2]\n","[unused3]\n","[unused4]\n","[unused5]\n","[unused6]\n","[unused7]\n","[unused8]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PPmt-9mKOqjC","executionInfo":{"status":"ok","timestamp":1603895273351,"user_tz":-330,"elapsed":1170,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"cf3faea0-f9e9-4f5a-e25f-cbbd104dac5c","colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["!head -n 10 /outputs/special_tokens_map.json"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{\"unk_token\": \"[UNK]\", \"sep_token\": \"[SEP]\", \"pad_token\": \"[PAD]\", \"cls_token\": \"[CLS]\", \"mask_token\": \"[MASK]\"}"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MboOzLHLOvJO","executionInfo":{"status":"ok","timestamp":1603895280515,"user_tz":-330,"elapsed":1449,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"9d02cdf4-d10b-462d-c782-649b0bb24cb5","colab":{"base_uri":"https://localhost:8080/","height":381}},"source":["!head -40 /outputs/config.json"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VZOEU5l0O0A2","executionInfo":{"status":"ok","timestamp":1603895309320,"user_tz":-330,"elapsed":1214,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"86f0c2bf-ef28-4e17-c1b2-2619847a20e3","colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["# Load cached data and see\n","from transformers import BertTokenizer\n","tokenizer = BertTokenizer.from_pretrained(\"/outputs\")\n","print(tokenizer.encode(\"assets component acquired Company liabilities aircraft assumed substantially 2000 support Hermetic certain company\"))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[101, 7045, 6922, 3734, 2194, 22393, 14680, 2948, 5071, 12381, 2456, 2490, 2014, 11368, 2594, 3056, 2194, 102]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1h23jiqiPCs_","executionInfo":{"status":"ok","timestamp":1603895320073,"user_tz":-330,"elapsed":1463,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"d6c3661f-0103-458a-a58b-0a4e2f4f9184","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from transformers import pipeline\n","help(pipeline)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Help on function pipeline in module transformers.pipelines:\n","\n","pipeline(task:str, model:Optional=None, config:Union[str, transformers.configuration_utils.PretrainedConfig, NoneType]=None, tokenizer:Union[str, transformers.tokenization_utils.PreTrainedTokenizer, NoneType]=None, framework:Union[str, NoneType]=None, use_fast:bool=False, **kwargs) -> transformers.pipelines.Pipeline\n","    Utility factory method to build a :class:`~transformers.Pipeline`.\n","    \n","    Pipelines are made of:\n","    \n","        - A :doc:`tokenizer <tokenizer>` in charge of mapping raw textual input to token.\n","        - A :doc:`model <model>` to make predictions from the inputs.\n","        - Some (optional) post processing for enhancing model's output.\n","    \n","    Args:\n","        task (:obj:`str`):\n","            The task defining which pipeline will be returned. Currently accepted tasks are:\n","    \n","            - :obj:`\"feature-extraction\"`: will return a :class:`~transformers.FeatureExtractionPipeline`.\n","            - :obj:`\"sentiment-analysis\"`: will return a :class:`~transformers.TextClassificationPipeline`.\n","            - :obj:`\"ner\"`: will return a :class:`~transformers.TokenClassificationPipeline`.\n","            - :obj:`\"question-answering\"`: will return a :class:`~transformers.QuestionAnsweringPipeline`.\n","            - :obj:`\"fill-mask\"`: will return a :class:`~transformers.FillMaskPipeline`.\n","            - :obj:`\"summarization\"`: will return a :class:`~transformers.SummarizationPipeline`.\n","            - :obj:`\"translation_xx_to_yy\"`: will return a :class:`~transformers.TranslationPipeline`.\n","            - :obj:`\"text-generation\"`: will return a :class:`~transformers.TextGenerationPipeline`.\n","            - :obj:`\"conversation\"`: will return a :class:`~transformers.ConversationalPipeline`.\n","        model (:obj:`str` or :obj:`~transformers.PreTrainedModel` or :obj:`~transformers.TFPreTrainedModel`, `optional`):\n","            The model that will be used by the pipeline to make predictions. This can be a model identifier or an\n","            actual instance of a pretrained model inheriting from :class:`~transformers.PreTrainedModel` (for PyTorch)\n","            or :class:`~transformers.TFPreTrainedModel` (for TensorFlow).\n","    \n","            If not provided, the default for the :obj:`task` will be loaded.\n","        config (:obj:`str` or :obj:`~transformers.PretrainedConfig`, `optional`):\n","            The configuration that will be used by the pipeline to instantiate the model. This can be a model\n","            identifier or an actual pretrained model configuration inheriting from\n","            :class:`~transformers.PretrainedConfig`.\n","    \n","            If not provided, the default for the :obj:`task` will be loaded.\n","        tokenizer (:obj:`str` or :obj:`~transformers.PreTrainedTokenizer`, `optional`):\n","            The tokenizer that will be used by the pipeline to encode data for the model. This can be a model\n","            identifier or an actual pretrained tokenizer inheriting from :class:`~transformers.PreTrainedTokenizer`.\n","    \n","            If not provided, the default for the :obj:`task` will be loaded.\n","        framework (:obj:`str`, `optional`):\n","            The framework to use, either :obj:`\"pt\"` for PyTorch or :obj:`\"tf\"` for TensorFlow. The specified framework\n","            must be installed.\n","    \n","            If no framework is specified, will default to the one currently installed. If no framework is specified and\n","            both frameworks are installed, will default to the framework of the :obj:`model`, or to PyTorch if no model\n","            is provided.\n","        use_fast (:obj:`bool`, `optional`, defaults to :obj:`False`):\n","            Whether or not to use a Fast tokenizer if possible (a :class:`~transformers.PreTrainedTokenizerFast`).\n","        kwargs:\n","            Additional keyword arguments passed along to the specific pipeline init (see the documentation for the\n","            corresponding pipeline class for possible values).\n","    \n","    Returns:\n","        :class:`~transformers.Pipeline`: A suitable pipeline for the task.\n","    \n","    Examples::\n","    \n","        >>> from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer\n","    \n","        >>> # Sentiment analysis pipeline\n","        >>> pipeline('sentiment-analysis')\n","    \n","        >>> # Question answering pipeline, specifying the checkpoint identifier\n","        >>> pipeline('question-answering', model='distilbert-base-cased-distilled-squad', tokenizer='bert-base-cased')\n","    \n","        >>> # Named entity recognition pipeline, passing in a specific model and tokenizer\n","        >>> model = AutoModelForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n","        >>> tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n","        >>> pipeline('ner', model=model, tokenizer=tokenizer)\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QjM1y-pJQkXq","executionInfo":{"status":"ok","timestamp":1603895332748,"user_tz":-330,"elapsed":9486,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"5e705678-e853-42e5-d6cc-1121df537a3c","colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["fill_mask = pipeline(\n","    \"fill-mask\",\n","    model=\"/outputs\",\n","    tokenizer=\"/outputs\"\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of BertModel were not initialized from the model checkpoint at /outputs and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"p06O0A8CMBI1"},"source":["### Do a quick check of the new model on fill in the blank task"]},{"cell_type":"code","metadata":{"id":"aazxrqRNQrpf","executionInfo":{"status":"ok","timestamp":1603895342815,"user_tz":-330,"elapsed":1146,"user":{"displayName":"Vimla Tayal","photoUrl":"","userId":"13436389996906844368"}},"outputId":"1c12e5f9-50ec-4dcc-e0d4-8bc48a6db5bf","colab":{"base_uri":"https://localhost:8080/","height":384}},"source":["result = fill_mask( \"Company would materially occurred [MASK] results operations different 2001 beginning acquisition\")\n","result"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'score': 0.027501985430717468,\n","  'sequence': '[CLS] company would materially occurred financial results operations different 2001 beginning acquisition [SEP]',\n","  'token': 3361,\n","  'token_str': 'financial'},\n"," {'score': 0.022655580192804337,\n","  'sequence': '[CLS] company would materially occurred following results operations different 2001 beginning acquisition [SEP]',\n","  'token': 2206,\n","  'token_str': 'following'},\n"," {'score': 0.017097260802984238,\n","  'sequence': '[CLS] company would materially occurred company results operations different 2001 beginning acquisition [SEP]',\n","  'token': 2194,\n","  'token_str': 'company'},\n"," {'score': 0.016840597614645958,\n","  'sequence': '[CLS] company would materially occurred the results operations different 2001 beginning acquisition [SEP]',\n","  'token': 1996,\n","  'token_str': 'the'},\n"," {'score': 0.01670217514038086,\n","  'sequence': '[CLS] company would materially occurred without results operations different 2001 beginning acquisition [SEP]',\n","  'token': 2302,\n","  'token_str': 'without'}]"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"m2FCk9orQ6t2"},"source":[""],"execution_count":null,"outputs":[]}]}